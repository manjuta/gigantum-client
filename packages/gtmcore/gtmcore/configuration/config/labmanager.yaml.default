# Configuration File for the Gigantum LabManager

# Extend/Modify an existing configuration file. If only file name provided, will assume in the same directory
from: null

# Core configuration
core:
  # Should the LabManager run in Team Mode (multi-user)
  team_mode: false
  # Location of configuration file for the LabManager logger
  logging_config: "/etc/gigantum/logging.json"
  # Should the app import a labbook into new user's working dirs on first login
  import_demo_on_first_login: true

# Project Container Configuration
container:
  # If null, no limit
  # To set enter string with a units identification char (e.g. 100000b, 1000k, 128m, 1g)
  memory: null

  # If null, no limit
  # To set enter a float for the CPU allocation desired. e.g. 4 CPUs available, 1.5 limits container to 1.5 CPUs
  cpu: null

  # If null, do not set shared memory parameter when launching project container
  # To set enter string with a units identification char (e.g. 100000b, 1000k, 128m, 1g)
  # This parameter is only set when a Project is GPU enabled and being launched with nvidia docker runtime
  gpu_shared_mem: 2G

# Authentication Configuration
auth:
  client_id: 0Ajo8Ov6Qriafo0xVpSyejWy1pwNWdhk
  provider_domain: gigantum.auth0.com
  audience: api.gigantum.io
  signing_algorithm: RS256
  identity_manager: local

# Environment Management Configuration
# URLs can specify a non-default branch using the format <url>@<branch>
environment:
  repo_url:
    - "https://github.com/gigantum/base-images.git"

# Git Configuration
git:
  backend: "filesystem-shim"
  working_directory: "~/gigantum"
  default_remote: "repo.gigantum.io"
  lfs_enabled: true
  remotes:
    repo.gigantum.io:
      remote_type: gitlab
      admin_service: usersrv.gigantum.io
      index_service: api.gigantum.com/read
      object_service: api.gigantum.com/object-v1


# Embedded Detail Object Database config
detaildb:
  logfile_limit: 8000000
  options:
    compress: true
    compress_min_bytes: 4000

# LabBook Lock Configuration
lock:
  redis:
    host: localhost
    port: 6379
    db: 3
    strict: true
  reset_on_start: true
  timeout: 120
  expire: null
  auto_renewal: false

# Flask Configuration
flask:
  DEBUG: true
  TESTING: true
  allow_cors: true

# Details for route proxying
proxy:
  # The host for the proxy control (to manipulate routes)
  api_host: localhost
  # The port for the proxy control
  api_port: 1999
  # All inbound requests (to be proxied) arrive
  # at 0.0.0.0 on the following port
  external_proxy_port: 10000
  # Port from the perspective of the UI that the proxy
  # is available from
  apparent_proxy_port: 10000
  # All LabManager api traffic has this default prefix.
  labmanager_api_prefix: /api

# Datasets configuration
datasets:
  cache_manager: "host"
  hash_cpu_limit: "auto"
  # For download_cpu_limit and upload_cpu_limit:
  #   - "auto": will set number of workers based on number of cores with a max of 8
  #   - <int>: will use the number of workers specified. Useful when you want to limit workers or use more than 8
  download_cpu_limit: "auto"
  upload_cpu_limit: "auto"
  backends:
    gigantum_object_v1:
      # File size in bytes that will trigger a multipart vs. traditional upload.
      # Also used as the size of each part (16 MiB)
      multipart_chunk_size: 16777216
      # Number of bytes to read and send during a PUT request (1 MiB)
      upload_chunk_size: 1048576
      # Maximum number of bytes to download from the stream at a time before writing to disk (4 MiB)
      download_chunk_size: 4194304
      num_workers: 4
    public_s3_bucket:
      # 4 MiB
      download_chunk_size: 4194304

# Dispatcher and permitted number of workers -
# NOTE! Only the default queue is burstable
dispatcher:
  gigantum_default_queue: 7
  gigantum_build_queue: 1
  gigantum_publish_queue: 4